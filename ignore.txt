困则思变
现在的状态真是让我恶心而又无力。
浑浑噩噩的当着撞钟的和尚，忘记了什么叫努力，也放弃了变得更好。
连努力的勇气都没有，却开始了反问为什么？
为什么？因为你现在还很弱小啊！

是时候了，是时候重新站起来了！

目标：Ping++,23K+
list:
linux(ubuntu)，熟练的包管理，IDE（php/go），init.d，cpu/内存/硬盘/IO/监控/流量，shell脚本。
Git
php，支付对接，框架（？） composer
nginx服务器配置  顺便压测   负载均衡
mysql 锁（随便了解）  数据库主从
GoLang   包形式
VPN      ok

加油！




linux:
ubuntu安装成功（vmware）：
    ubuntu/win10双系统安装：
	充满血泪的两天。
	现在开机启动方式有两种：BIOS（旧式启动）/UEFI（新式启动）  两者在我的电脑上可以兼容同时存在。 Bios是结合　ｍbr文件引导，UEFI是结合efi文件引导。
	目前，win10默认安装后选择UEFI方式启动。Ubuntu也支持uefi方式启动。
	可以直接将ISo文件解压到U盘中，在UEFI中设置从U盘启动，程序会自动找到UEFI文件夹下完成引导。
	其次，微软有一个secure boot项目，用于保护自身的操作系统，可以在UEFI中关闭。
	遇到的坑。。。。。。
	首先，双显卡问题。双显卡在进入启动项目后会出现卡死/黑屏等一些情况，可以在引导菜单出现后。按E 进入文件编辑。添加nomodeset项目。避免出现驱动冲突。
	U盘问题。通过BIOS引导。出现a required file is missing or contains errors.... 通过UEFI引导usb device read error/unable to find a medium containing a live file system。只能确定是硬件问题，始终无法定位到问题的所在。最后，，，换U盘搞定。。。（usb3.0->usb2.0)

linux下安装xp虚拟机：
     使用virtualBox安装雨林木风ghostXP失败，更换为vmware player。
     使用PQ分区，主分区（C）逻辑分区（D），注意，主分区要设置为作用的。否则安装后开机将会引导失败！
网络配置（linux）下






开启3d加速后瞬间不卡。
联网方式 host-only  只要保证ubuntu内的IP设置和VMnet1在一个网段即可，ping通
主机、虚拟机不能共享剪切板问题：重新安装vmware tools
输入法：sogou
Linux下的输入法是基于一个底层框架，有ibus/fcitx

全民wifi上网问题：
在安装了官方驱动后，成功上网一段时间，出现系统崩溃。
ubuntu klyin的kernal是3.X kernel没有集成mt7601驱动，
因此，尝试选择其他方案：
ppa:thopiekar/mt7601

包管理：
	apt-get 
	1.定位包 
	dpkg -l | grep reminders   dpkg -l 列出所有安装的包
	or

	dpkg -S file–>这个文档属于哪个已安装软件包 
	dpkg -L package–>列出软件包中的任何文档

	dpkg -r package 删除包（保留配置）
	dpkg -P package 删除 （不保留配置）

	ppa源：实质上就是https://launchpad.net/ubuntu/+ppas 这个网站上一个对应的ID，用来下载该用户提交的应用
	sudo add-apt-repository ppa:user/ppa-name  添加ppa源
	sudo apt-get update  更新源
	此时就可以在系统中查看、安装对应的软件
	apt-cache search mt7601
	apt-get install mt7601-sta-dkms

	apt-get build-dep 可以解决依赖。
	最好不使用源码安装，一定要使用源码安装的话，务必制定--prefix参数。
	

模块相关：
	lsmod  列出 已经加载 的模块
	cat /lib/modules/'uname -r' /modules.dep 可以查看所有的系统模块 包括未加载的。
	modprobe XXX 加载模块
	modprobe -r XXX 删除模块



使用PPA源 安装完成后，已经可以在modules.dep中看到该模块：
root@ubuntu:/lib/firmware# cat /lib/modules/4.2.0-16-generic/modules.dep| grep mt7601
kernel/drivers/net/wireless/mediatek/mt7601u/mt7601u.ko: kernel/net/mac80211/mac80211.ko kernel/net/wireless/cfg80211.ko
updates/dkms/mt7601Usta.ko:

可以看到有两个ko，一个是kernel自带的 mt7601u ，一个是新安装的 mt7601Usta。
加载： 
modprobe mt7601Usta  
lsmod已经可以看到  mt7601Usta  了。



翻墙（搞定）
shadowsocks(ss-qt5) +  switchysharp
shadowsocks 建立与VPS（my hosts)的连接。通过指定的本地接口转发请求。
因此，在ss执行后，需要设置代理。
直接使用IE代理，或者360内的代理，会将所有的请求都转发到ss上，因此，我们需要一个软件来自动切换。例如访问国内站点时，不走ss，访问google时，则采用ss。这样就可以最大程度保证访问的通畅。
swichysharp采用自动切换。有现成的配置文件。可以直接导入。
所谓的在线规则就是指定乱七八糟的一大堆网址，请求的时候转发到自己的ss上，没什么大不了的。


（lantern 待研究）
关于chromeGae  其实就是 集成了 chrome/switchyOmega/lantern 的合计。
lantern启动后，会将请求转发到8787端口上。
switchyOmege则是负责配置需要转发的请求。





ubuntu下首次提交
vi:
问题：
   ubuntu中vi在编辑状态下方向键不能用，还有回格键不能删除等我们平时习惯的一些键都不能使用。

解决办法：
   可以安装vim full版本，在full版本下键盘正常，安装好后同样使用vi命令。
安装vim：
 ubuntu预装的是vim tiny版本，而需要的是vim full版本。执行下面的语句安装vim full版本：
   $sudo apt-get remove vim-common
   $sudo apt-get install vim




git:
windows下，bash可以正常使用git push/pull命令。
cmd提示Permission denied (publickey)。
原因是没有设置%HOME%环境变量，添加%HOME%为包含.ssh的文件夹路径（一般是C:/users/XX）

使用ssh-agent可以避免每次push的时候都要重复输入帐号密码。

git 默认只会找~/.ssh/id_rsa的key，因此要支持多账户，则需要使用.ssh/config

1、配置github ssh，避免push时反复提交密码
	ssh-keygen -t rsa -b 4096 -C "your_email@example.com"
	eval "$(ssh-agent -s)"
	ssh-add ~/.ssh/id_rsa
	Add the SSH key to your GitHub account.（公钥添加）
	测试是否正确：
	ssh -T git@github.com
	如果提示：
	Hi username! You've successfully authenticated, but GitHub does not
provide shell access.则表示正确配置。

坑：理论上提示出现以后，push时已经可以自动push而不需要反复输密码，出现了这种原因后，经过排查：
SSH forwarding only works with SSH URLs, not HTTP(s) URLs. Check the .git/config file on your server and ensure the URL is an SSH-style URL like below:

[remote "origin"]
  url = git@github.com:yourAccount/yourProject.git
  fetch = +refs/heads/*:refs/remotes/origin/*
  修改后即可正常运行。

2、多账户
在.ssh目录下
	a 新增一个ssh key  ssh-keygen -t rsa -C "liucj@2345.com"，新增时，会提示id_rsa已经存在，输入一个新的文件名。则公钥私钥都会保存在新文件名中
	
	b 新建config文件。内容：
	Host gitlab245
	  HostName 172.16.0.245 
	  User liucj@2345.com
	  IdentityFile ~/.ssh/gitlab245

	c add ssh key to ssh-agent
	  eval "$(ssh-agent -s)"
	  ssh-add ~/.ssh/gitlab245
	
	d test ssh connect 
	ssh -T git@172.16.0.245 

查看本地分支对应的远程分支 
git branch -vv


进程/线程
一个CPU单次只能处理一个进程（一个程序）
因此，在多核CPU上为了能够更大程度利用CPU，大部分程序都会对多线程做支持。

关于多进程 （多进程单线程） 好还是多线程（单进程多线程）好 ，众说纷纭我也不知道。。。

另：（关于php单线程）
php本身不支持多线程，用来处理数据运算很蛋疼。但是，并不意味着php不能处理网络请求，因为
网络请求的线程是由服务器！！来建立的。而php本身有自己的进程管理器（比如php-fpm），每个
请求过来后都会创建一个Php进程与服务器通信，断开后销毁进程。
创建一个进程的消耗要大于线程，但难度要小于线程（不涉及到内存共享之类）



goroutine的 RWMutex（读写锁）
当多个线程操作一个共享内存时（例如写数据）可能会出现异常情况。
因此为了保证数据正确性，多个goroutine时要注意锁的使用。

读写锁是针对读写的互斥锁
基本遵循两大原则：
1、可以随便读，多个goroutine同时读
2、写的时候，啥也不能干。不能读也不能写




linux 命令

分割字符串：
cut awk
mysql5.6 - XXXXXXXX
cut :
	cut -d' ' -f1    //-d后面为分隔符   空格为‘  ‘
awk:
	awk '{print $1}' // -F后面为分隔符   默认为空格    命令需要放在'{}'内
	awk 的命令中可以写程序/逻辑判断等    例如  '{if($1>0){print $1,$2}}'  去重 '{if (a[$1]!=1){print $1;a[$1]=1;}}'  //看上去像PHP语法
	awk内置变量
	ARGC    命令行参数的个数
	ARGV    命令行参数数组
	ARGIND 当前被处理文件的ARGV标志符
		利用ARGIND可以逐个处理待处理的文件
	NR 　　已经读出的记录数
	FNR   　当前文件的记录数
	数组：  	{if(!a[$1]){a[$1]=1;b[$6]+=1;}}END{for(i in b){print i,b[i];}}   长度 length(a);
	多维数组，只支持组合的数组（a[$1,$2]=1） 实质上并非多维数组 ，只是键值组合起来  。a[$1 SUBSEP $2]=1 

xargs  
	参数：
	注意：参数并不是逐行输入，如果要求每次只输入一个参数需要指定
	-n 1
	-P 4:控制并发，可以并发执行命令，（注意，可能会出现异常，共享内存/锁竞争等）
	-t 执行前先打印出命令
	-I 使用特殊字符（默认{}）代替参数 
	ls|xargs wc -l    将前面标准化输出的结果逐行作为 命令参数执行
       当执行的命令有多个参数时，可以使用bash -c :
	echo a b c | xargs -l -n 1 bash -c 'echo $0 $1 $2'





ps 进程查看
	参数
	参数有几类：
	1 /   进程选择参数   指定输出哪一些进程
	a 终端机下的所有程序
	x 非终端机下所有进程
	-A /-e 所有进程
	所以 ps -A 实质上等于 ps ax

	2/ 指定进程参数     指定的命令名/PID/groupID
	-p 111
	-C watch/bash	

	3/输出结果控制参数
	-f 全格式
	-j 作业模式
	-l 长格式
	u  用户模式
	-o format    输出用户定义的格式例如 %cpu,%mem,pid,psr,args等等

	4/输出结果修饰参数   在输出的结果基础上进行修饰
	c 只输出命令名  不输出参数/路径等   （参数太长不看）
	O order 排序


	5/  线程相关参数
	-L 输出线程 ，包括LWP（线程id)
	 
	输出控制选项 （可以作为-o 参数）
	非常多，几个有意思的：
	args   执行命令（包括参数/路径）
	comm	 只有命令（不包括参数路径）
	psr    进程（or线程）目前在哪个CPU上工作

最后，监控go的goroutine具体情况命令：
watch -n 1 'ps -eLo s,pid,ppid,lwp,%cpu,%mem,args,psr|grep goroutine'    可以看到当前的goroutine线程  具体分布在哪个CPU上面，cpu占用情况等一系列数据。

查看进程命令绝对路径：
在/proc/目录下有对应PID的文件夹，进去ll 一目了然



shell
	获取上一条命令执行的结果:$?    1表示失败 0表示成功


解压
unzip
	unzip -O cp936 -d E_bak E.zip
	-O cp936 解决解压文件名乱码的问题


curl
	参数
	-I 只响应头部信息
	-H 自定义头信息传递给服务器
	curl -H "Host:jifen.2345.com"  http://172.16.0.1/index.php


内存相关：
free -m 查看内存
swapoff  顾名思义，关闭swap,会将swap里的数据全部都放入内存中。一般释放swap的操作为：
swapoff -a;swapon -a;
如果提示：
swapoff: /dev/sdb6: swapoff failed: Cannot allocate memory
很明显，内存空间不足，不够存下所有swap空间的内容。所以关点东西，清一下内存就OK啦/

释放内存cache（貌似意义不大）：
第一步    sync

通过修改proc系统的drop_caches清理free的cache
echo 3 > /proc/sys/vm/drop_caches




fastcgi相关：
apache 对PHP的解析有三种方式：
mod_php	模块方式
php_fpm  fastcgi方式 （apache 对应的模块：2.2  mod_fgid（错误） mod_fastcgi  2.4 mod_proxy_fgid ）

mod_php 
传统方法，默认的方式。
优点：配置简单
缺点：开销大  最重要的  修改php.ini后需要重启apache!


php-fpm
php的fastcgi实现。
优点：开销小于mod方式。最重要的，修改php.ini不需要重启apache!
缺点：配置复杂？？


(可以尝试一下 fastcgi 实现php支持）

php-cgi  和 php-fpm是php的cgi的两种实现方式。
php-fpm效率要大大优于php-cgi

apache的mod_fgid核mod_fastcgi的指令集完全不同，mod_fgid并不支持外部服务器，因此也不可能









crontab
crontab -l 列出当前用户的Crontab项目
-u user	指定用户
-e 编辑crontab
-r 删除当前用户的crontab文件

对crontab的编辑生成的文件为/var/spool/cron/crontabs/User
crontab日志 ：可以在/var/log/syslog中查看


munin 总结：
蛋疼的玩意儿
munin linux服务器上的一个监控软件。分为server端和node端两部分
sudo apt-get install munin munin-common munin-node 

流程：
munin-node启动后会监听一个端口（默认4949），用户munin服务端来获取数据

服务端定时发送请求向node端收集监控信息，然后将结果保存在一个文件夹中，供http服务器生成结果页面。
因此需要apache等http服务器环境。

在munin.conf配置中，可以指定
html_strategy cron
则munin会以cron的方式定时去node端获取数据。   除此之外还可以设置cgi(暂不了解这么做的意义---)

生成的结果页面中，所有的监控项目最低的显示单位是by day。
点进去发现图片没有显示，原因是munin需要cgi支持，动态生成图片结果。
所以在http上面安装cgi扩展
apt-get install libapache2-mod-fcgid
在apache.conf中配置location，fastcgi相关设置。

如果仍然不能显示图片，提示500错误。尝试安装CGI::Fast Perl module
 apt-cache show libcgi-fast-perl



sed命令   输出一列连续的数字（一般用在shell中）
-w	 固定长度输出   sed -w 1 10  output:01 02 ....10
-f ”%3g"  指定宽度，不满前面补空格




date命令
+"FORMAT"  格式化时间    date +"%Y%m%d"
-d "string" 	解析一个时间字符串。  date -d "a week ago"

时间戳与时间互相转换
date -d "20160101" +"%s"

date -d "1970-01-01 UTC 1451577600 secodes" +"%Y%m%d"




nfs远程挂载
 mount -t nfs 172.16.9.18:/home/lcj/code/pc.50bang.org /opt/case/liucj/


ftp的传输方式有两种，ascii和二进制
ascii方式传输，ftp会自动调整内容以便把文件存储成目标机器的文本格式
二进制方式传输，则不会转换调整内容


ldd file 
查看某个可执行程序所需的共享库
/etc/ld.so.conf 指定动态链接库的目录，修改后使用ldconfig重新生成。




service的开机启动设置
乱七八糟的。。。
传统的启动服务使用： /etc/init.d/XXX方式启动
/etc/init/是init.d的替换演化版本
service可以兼容两者。因此可以使用 service XXX start 来启动

开机启动：

可以使用  update-rc.d apache disable 方式（类似红帽下的chkconfig）
if Upstart job definitions do not have an update-rc.d command. 
可以编辑文件。
mv /etc/init/smbd.conf /etc/init/smbd.conf.disabled
实现开机不启动


grep命令
-r  递归查询目录下的文件夹内容。
-H 查询的结果带文件名，查询多个文件时为默认选项
-v 查询不匹配的所有结果。
grep -Hr "^[^;]" /etc/php  查询没有注释的php.ini内容
也可以
grep -Hrv "^[;]" /etc/php


远程访问共享文件夹：
linux下访问局域网内的windows共享文件，可以使用smb服务
直接在资源管理器中输入  smb://172.16.20.249/
输入用户名密码
即可访问。
linux远程挂载：
 mount //172.16.20.249/E /opt/data/ -o username=×××,password=××× -t cifs

umount -f /opt/case/liucj 强制卸载







tip:
只列出文件：
ls -l | grep ^[^d] | awk '{print $9}'
列出完整路径
find ./



又回去搞php了，哈哈哈哈



linux下的svn gui工具可以使用rabbitvcs，rabbitvcs对不同的桌面环境都有对应的软件，gnome,kde,以及mint下面的nemo-rabbitvcs，效果一流
gedit下，中文乱码的解决：
gconftool-2 --set --type=list --list-type=string /apps/gedit-2/preferences/encodings/auto_detected "[BIG5,UTF-8,CURRENT,ISO-8859-15,UTF-16]"





#ssh#
ssh相关命令：

##一  ssh是一种网络协议，用于计算机之间的加密登陆，如果使用ssh登陆远程计算机，密码将会加密，即使中途截获也不会被泄露。##
##二 中间人攻击##
ssh登陆过程：
1 远程主机收到登陆请求，把自己的公钥发给用户
2 用户使用公钥，将登陆密码加密后发送回来
3 远程主机使用自己的私钥解密密码，如果正确就同意登陆
风险：
如果有人冒充远程主机，截获了请求，将自己伪造的公钥发送给用户，那么用户很难辨别真伪。因为不像https协议，SSH协议的公钥是没有证书中心（CA）公证的，也就是说，都是自己签发的。
可以设想，如果攻击者插在用户与远程主机之间（比如在公共的wifi区域），用伪造的公钥，获取用户的登录密码。再用这个密码登录远程主机，那么SSH的安全机制就荡然无存了。这种风险就是著名的"中间人攻击"（Man-in-the-middle attack）。

##登陆##
1 口令登陆
如果是第一次登陆远程主机，会出现：
$ ssh user@host
　　The authenticity of host 'host (12.18.429.21)' can't be established.
　　RSA key fingerprint is 98:2e:d7:e0:de:9f:ac:67:28:c2:42:2d:37:16:58:4d.
　　Are you sure you want to continue connecting (yes/no)?
如果接受：yes
则表明用户接受该公钥 开始输入密码

所有用户授信登陆的主机 都会保存在 $HOME/.ssh/know_hosts文件中，下次再登陆时，如果在know_hosts中找到，则跳过授信过程直接输入密码登陆

2 公钥登陆
原理：将用户的公钥存储在远程主机上，登陆时，远程主机发送一段随机字符串过来，用户用自己的私钥加密后发回，主机使用公钥解密，如果结果一致，则同意登陆。
过程：
1> 生成密钥  ssh-keygen
2>发送密钥至远程  ssh-copy-id user@host，
3> 如果不行，检查远程 /etc/sshd/sshd_config ,下面注释是否去掉：
	RSAAuthentication yes
　　PubkeyAuthentication yes
　　AuthorizedKeysFile .ssh/authorized_keys
4>重启
	service ssh restart
注意：发送公钥至远程，实质上是将.pub的内容append到远程.ssh/authorized_keys文件末尾


##命令##
简单：
ssh -p 2222 user@host
生成密钥
ssh-keygen -b 1024 -t rsa 
在know_hosts中寻找信任主机：
ssh-keygen -H -F [host]:port
从know_hosts中删除主机：
ssh-keygen -R [hostname]:port    eg: ssh-keygen -R [45.62.111.76]:27027   ##if works,it will display '# Host [45.62.111.76]:27027 found: line 1 type RSA'
发送密钥到远程主机：
实质上是发送公钥，即后缀.pub文件
ssh-copy-id [-i [identity_file]] [-p port] [username@][host]

ssh-copy-id -i .ssh/myvps.pub -p 27027 45.62.111.76  
使用该命令后，完美登陆。比对远程服务器$HOME/.ssh/authorized_keys与本地$HOME/.ssh/myvhost.pub内容  一模一样




#SSL/TLS协议#
HTTP通信具有三个风险：
窃听 / 篡改 /冒充
SSL/TLS协议就说为了解决这些风险而设计的。

##运行##
基本思路采用公钥加密法：客户端向服务器索要公钥，然后使用公钥加密信息，服务器收到密文后用自己的私钥解密。
补充：
上面只是简单的流程，实际的流程要复杂不少，主要的概念有，对称加密/非对称加密。
1.客户端生成【随机数1】，客户端（通常是浏览器）先向服务器发出加密通信的请求，发送【随机数1】，向服务器端索要公钥；  
2.服务器收到客户端请求后，生成【随机数2】，向客户端发出回应，回应信息包括【随机数2】，服务器证书(包含公钥)  
3.客户端收到后，验证服务器证书的有效性，取出公钥，生成【随机数3】，使用公钥加密【随机数3】，发给服务器。  
4.服务器回应， 至此，服务器和客户端都有3个随机数，使用3个随机数生成这次的会话秘钥(即对称秘钥)，二者开始使用对称加密通讯。服务器通知客户端：编码改变通知，表示随后的信息都将用双方商定的加密方法和密钥发送。服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时也是前面发送的所有内容的hash值，用来供客户端校验(对称加密)。
5.之后二者将通过对称加密来通讯。

- 非对称加密：简单说就是使用公钥加密后的密文只是使用对应的私钥解密，即：需要私钥/公钥两组密钥。
- 对称加密：文件加密和解密使用相同的密钥





因此 https就是将http协议经过一层ssl协议加密包装

##openssl##
开源社区提供的一套工具包，包括了主要的密码算法，证书密钥封装管理功能。


##信息摘要##
对数据进行处理，得到一段固定长度的结果。
openssl提供的摘要算法有md4、md5、ripemd160、sha、sha1、sha224、sha256、sha512、sha384、wirlpool。可以通过openssl dgst 查看

##数字签名##
数字签名：数字签名其实分成两步，首先对原始文件进行摘要运算，得到摘要值，然后使用公开密钥算法中的私钥对摘要值进行加密。

1. 明文------------------->摘要------------------------>数字签名
     单向hash                    甲方私钥加密

2. 明文------------------->摘要\
		单向hash	\----->是否相等
   数字签名--------------->摘要/
	      甲方公钥解密


##SSL使用证书来创建安全连接。有两种验证模式：##

1. 仅客户端验证服务器的证书，客户端自己不提供证书；

2. 客户端和服务器都互相验证对方的证书。
安全性第二种更高，一般网上银行会使用第二种，普通web网站使用第一种。

##部署流程##
1. 颁发证书：
分类：  按照签名方式有：自签名（根证书），CA签名 两种形式。
自签名：
	1. 生成一个私钥：		openssl genrsa -des3 -out server.key 4096
	2. 生成签名请求 ：            openssl req -new -key server.key -out server.csr  #利用私钥做出一个签名请求
	3. 对上一步签名请求进行签名：   openssl x509 -req -days 365 -in server.csr -signkey server.key -out server.crt     #签名请求后缀.csr(certificate signing request)  证书后缀 crt
	
	简单的一个命令处理上面的：openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout apache.key -out apache.crt
	该证书无法被吊销，因此要确保私钥安全。

CA签名：
	私有CA：本质上就是用一个自签名的证书对一个签名请求做签名：
	1. 生成自签名证书（根证书） openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout apache.key -out ca.crt
	2. 生成服务端私钥：	  openssl genrsa -des3 -out server.key 4096
	3. 生成签名请求： openssl req -new -key server.key -out server.csr 
	4. 用生成的CA证书对请求做签名： openssl x509 -req -days 365 -in server.csr -CA ca.crt -CAkey ca.key -set_serial 01 -out server.crt
	
2. 服务器配置：
https默认监听的端口为443，类似于http的80端口，是两个完全不相关的连接。
1. 开启ssl模块： 	a2enmod ssl
2. 配置文件：   在site-avaliable/000-default中。  <VirtualHost *:80> 。。。</VirtualHost>下增加  	<VirtualHost *:443> 。。。</VirtualHost>
加入：
	SSLEngine on
	SSLCertificateFile /etc/apache2/ssl/localhost.crt
	SSLCertificateKeyFile /etc/apache2/ssl/localhost.key
	SSLCACertificateFile /etc/apache2/ssl/localhost.crt
即可。
浏览器访问 ：https://localhost


	

  










#rsync#
rsync是一个远程数据同步工具，可以使用ssh 或者 rsync服务的方式同步文件：
rsync [OPTION]... SRC DEST    本地同步
rsync [OPTION]... SRC [USER@]host:DEST    ssh远程 
rsync [OPTION]... [USER@]HOST:SRC DEST 	ssh远程
rsync [OPTION]... [USER@]HOST::SRC DEST 	rsync服务远程
rsync [OPTION]... SRC [USER@]HOST::DEST 	rsync服务远程
rsync [OPTION]... rsync://[USER@]HOST[:PORT]/SRC [DEST]	rsync服务远程

##服务端##
服务端即目标服务器，需要开启rsync服务。
默认没有配置文件，创建  /etc/rsyncd.conf，包含基本的rsync信息，比如log pid lock位置，以及secrets file ，这个文件存放用户名:密码。 除了基本信息还有模块配置，比如命名一个www模块：
[www]
comment= backup web 
path=/opt/case/test
read only = no 
exclude=test 
auth users=www  #一定要在secrets file中有对应记录。

完成后开启服务：
rsync --daemon --config=/etc/rsyncd.conf 即可。

##客户端##
直接传输文件：rsync -avzP go-week/ www@172.16.0.151::www
输入密码，或者配置一个密码文件即可。
rsync -avzP --password-file=./rsync.pwd go-week/ www@172.16.0.151::www

##注意##
服务端客户端的文件权限必须都为600才行

##实时同步##
使用inotify+rsync的方式可以做到实时同步。


# docker#
##镜像## 
镜像是容器的基础，每个容器运行是都要指定其基础镜像。
##容器##
镜像（image）和容器（container）的关系就像面向对象中的 类 和实例一样。容器运行是，在以镜像为基础层，在上面增加了一个读写的存储层。
命令：
-  运行：docker run -itd -name myContainer ubuntu:14.04 /bin/echo 'hello world' 
-d 守护状态运行  -t 分配一个伪终端
-  查看: docker ps -a -q
-q 只显示ID
-  进入：docker attach ID
- 删除: docker rm 
删除所有：docker rm $(docker ps -a -q)
- 启动/结束/重启   docker start|stop|restart

进入容器：sudo docker exec -it 775c7c9ee1e1 /bin/bash 
容器信息：docker container inspect ***

##数据卷##

Q：重启后居然配置还在！！
A：当然在啊，只是设置后的配置不会保存到镜像（images)中。

##link 容器互联##
不需要固定的IP也可以实现基础的集群。核心就是 --link 指定好镜像和别名后，主从同步这块，从库设置的host为 别名，而非IP。同样，web服务器容器创建时也指定好--link与数据库容器做链接。连接时host设置为别名即可。
Q：虽然说使用别名可以解决重启容器IP变更的问题，BUT,如果要向一个容器添加新的link该如何是好？



#Docker#

##流程##
新建容器必须要基于一个镜像，例如我们需要一个apache+php的运行环境，就需要有一个apche+php的镜像。可以使用Docker Hub里的镜像，也可以自己编写Dockefile，定制自己的镜像。
###定制镜像###
FROM ubuntu
COPY sources.list /etc/apt/
RUN apt-get update && apt-get install -y apache2 libapache2-mod-php7.0\
   && rm -rf /var/lib/apt/lists/* 
CMD ["apache2ctl", "-D", "FOREGROUND"]
1. 定制镜像，则需要有一个镜像作为基础。因此指定FROM ubuntu指令。
2. 因为ubuntu默认的源速度很慢，因此我们使用了本地的一个sources.list文件作为源文件，使用COPY命令。 
3. 开始执行安装apache php 同时删除包的命令。
4. 指定命令：前台执行apache。
5. 编写完成后，开始生成镜像。
	docker build -t myapache:v1 .

6. 开始从镜像创建容器：
	docker run -d -p 80:80  -v PATH:/var/www/html myapache:v1  ## -d 以守护进场模式运行  -p 绑定container端口到宿主机端口 -v 挂载本地PATH到容器的/var/www/html下。

*注意*
1. 生成镜像时，我们会传入一个参数“.”， 这个参数指明的是dockerfile的上下文地址。执行docker build后会把上下文目录下的文件都发送给服务端。  在dockerfile中 有COPY指令，这里则可以使用上下文目录下的 sources.list文件。
2. 镜像默认的执行程序都是 /bin/bash。这也是docker区别于虚拟机的地方，容器对宿主机来说执行的程序始终都是 PID为1的程序，即默认程序。如果不替换默认程序，在docker容器中指定：service apache2 start 或者 apache2ctl start，则是使apache在后台执行。对于宿主机来说，容器的程序依然是/bin/bash，因此要将默认程序修改为apche,同时要指定其运行环境为前段而非后台。
3. sources.list的目录为 /etc/apt/... ，apt-get update的作用是从软件源里拉取所有的软件信息列表，如果不做这一步是获取不到软件的。
4. 这个技术碉堡了！




16.04 does not have PHP 5 in the official repositories. Install a 14.04 system, or use this PPA.

要想用docker安装php5  换个老点的ubuntu版本把










#mysql#
##权限##
GRANT [ALL|priv_type] on [tbl_name | * | *.* | db_name.*] To user IDENTIFIED BY [PASSWORD] 
IDENTIFIED BY后面的密码不需要使用PASSWORD函数加密。

##主从同步##
大体流程：
1. 主库开启bin_log，设置ＩＤ号，ｍｙ.cnf:
# 日志文件名  
log-bin = mysql-bin  
  
# 主数据库端ID号  
server-id = 1 
2. 重启，主库创建用于从库同步的账户：
mysql>grant replication slave on *.* to 'slave'@'%' identified by '123456';  
MySQL> flush privileges;
show master status;  

3. 从库添加ID：
server-id = 2

4. 从库设置设置主库信息：
mysql>change master to master_host='192.168.1.2',master_user='slave_account',master_password='123456',master_log_file='mysql-bin.000009',master_log_pos=196;  
mysql>start slave;  
mysql> show slave status\G; 
stop slave#停止同步。


添加完成后即可开始主从同步。主库的任何修改都会同步到从库。
其他配置：
主库：
binlog-do-db = test  #只同步test库
binlog-ignore-db = mysql    #忽略mysql库


错误处理：
stop slave; 
set global sql_slave_skip_counter=1; （1是指跳过一个错误）
slave start;


##binlog##
查看日志：	
show variables like "log%";
查看bin log:
mysqlbinlog mysql-bin.000001 
默认bin log中对行的操作都经过base64加密了，查看：
mysqlbinlog -v -v --base64-output=DECODE-ROWS mysql-bin.000001即可。

binlog在mysql重启后，或者log容量达到上限，后面的索引会递增。

##双主热备##


#高可用#
##mysql##
一般都是基于主从同步方案：
1. keepalived
2. MHA

一般使用主主同步，替换主从同步：
1.主从同步的话，主数据库出现问题要切换到从数据库，这时候从数据库新加入的数据无法（很难）再同步回主库‘
2. 主主同步主要的问题是，可能会出现主键冲突。可以通过设置两台数据库的：
auto_increment_increment=2
auto_increment_offset=1 
来保证主键错开。



##web##
##nginx##



##redis##


## 127.0.0.1 0.0.0.0区别
netstat 中可以看到可以看到各个服务绑定的host和端口， 127.0.0.1只允许本机访问，而0.0.0.0表示 “本机所有的IP” 包括各种局域网互联网IP。
一般每个软件各自都有会绑定设置。  






